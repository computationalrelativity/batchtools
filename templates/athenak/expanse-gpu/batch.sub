#! /bin/bash
@(#SBATCH -d afterok:@CHAINED_JOB_ID@)@
#SBATCH -A @ALLOCATION@ 
#SBATCH -t @WALLTIME@
#SBATCH -N @NODES@
#SBATCH --partition=gpu-debug
#SBATCH -J @SIMULATION_NAME@
#SBATCH --mail-type=ALL
#SBATCH --mail-user=@EMAIL@
#SBATCH -o @RUNDIR@/@SIMULATION_NAME@.out
#SBATCH -e @RUNDIR@/@SIMULATION_NAME@.err
#SBATCH --gpus=@NUM_GPUS_TOT@
#SBATCH --ntasks-per-node=@NUM_GPUS@
#SBATCH --mem=64G

echo "Preparing:"
set -x                          # Output commands
set -e                          # Abort on errors
cd @RUNDIR@

module purge
module restore
module purge
module load gpu/0.17.3b
module load slurm/expanse/23.02.7
module load gcc/10.2.0/i62tgso
module load openmpi/4.1.3/gzzscfu

echo "Checking:"
pwd
hostname
date

echo "Environment:"
env | sort > ENVIRONMENT
echo ${SLURM_NODELIST} > NODES

# Check for restart files
if [ -d parent/rst ]; then
  restart_files=$(ls -t parent/rst/*.rst)
  restart_file=(${restart_files[0]})
  restart_line="-r $restart_file"
  printf "\nrestarting from $restart_file\n\n"
else
  restart_line="-i @PARFILE@"
  printf "\nstarting from beginning\n\n"
fi

# set up for problem & define any environment variables here
export SLURM_CPU_BIND="cores"
export MPICH_GPU_SUPPORT_ENABLED=1

srun \
    -n $((@NODES@ * @NUM_GPUS@)) \
    -N @NODES@ \
    @EXECUTABLE@ \
    --kokkos-map-device-id-by=mpi_rank \
    -d @RUNDIR@ \
    -t @TERMINATION_TIME@ \
    $restart_line

# perform any cleanup or short post-processing here
